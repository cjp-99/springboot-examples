jSpringBoot-Redis使用说明
======================

> 目前操作redis的客户端有Jedis和Lettuce

Springboot-1.5.x 使用的Jedis,SpringBoot-2.x 使用的Lettuce。 

By default, if `commons-pool2` is on the classpath, you get a pooled connection factory.

## Redis知识

### redis 特性

1. 速度快 
   Redis是用C语言实现的；Redis的所有数据存储在内存中，用于快速地读写访问。

2. 持久化 
   Redis的所有数据存储在内存中，对数据的更新将异步地保存到磁盘上； 
   redis的持久化有两种方式：AOF与RDB两种模式

3. 支持多种数据结构 
   Redis支持五种数据结构：String、List、Set、Hash、Zset

4. 支持多种编程语言 
   Java、php、Python、Ruby、Lua、Node.js等

5. 功能丰富 
   除了支持五种数据结构之外，还支持缓存、事务、流水线、发布/订阅、消息队列等功能。 
   发布/订阅模型： Redis支持创建发布和订阅通道，这样Redis客户端可以订阅任意的通道来进行数据消费，并且任何已订阅该通道的客户端可以发布数据。

6. 主从复制 
   主服务器（master）执行写入（增删改），从（slave）服务器执行查询。复制提供可伸缩性和可用性。任何一个slave宕机，其他的slave还可以提供数据访问。

7. 虚拟内存 
   Redis使用RAM作为内存式存储。但是，在内存不足的情况下，它使用虚拟内存来保存数据。

8. 高可用及分布式 
   Redis-Sentinel（v2.8）支持高可用
   Redis-Cluster（v3.0）支持分布式

   

### redis客户端连接数

网络命令[linux命令总结之ip命令](https://www.cnblogs.com/ginvip/p/6367803.html)

```shell
ip route show
```

redis客户端介绍

 redis通过监听一个TCP端口或socket的方式接收来自客户端的连接，
 当与客户端建立连接后，redis内部会进行如下操作：
（1）客户端socket会被设置为非阻塞模式，因为redis在网络时间处理上采用的是非阻塞多路复用模型；
（2）然后为这个socket设置TCP_NODELAY属性，禁用Nagle算法；
（3）然后创建一个可读的文件事件用于监听这个客户端socket的数据发送。

**命令列表**

```shell
# 启动单机redis
nohup src/redis-server redis.conf > /redis.log 2>&1 &

# 在redis-cli命令行使用：info clients 可以查看当前的redis连接数
info clients 

# config get maxclients 可以查询redis允许的最大连接数
config get maxclients

# 在2.6之后版本，可以命令行修改最大连接数配置，默认10000，也可以在redis.conf配置文件中修改

# 命令行 可以设置redis允许的最大连接数
config set maxclients 10 

# 客户端命令集合
CLIENT HELP            # 获取帮助
CLIENT LIST       	   #获取客户端列表
CLIENT SETNAME <name>  #设置当前连接点redis的名称
CLIENT GETNAME         #查看当前连接的名称
CLIENT KILL ip:port    #杀死指定连接

# 其他命令 -c 集群,单机不需要
redis-cli -c -h 192.168.x.x -p 6379
quit：关闭连接（connection）
auth：简单密码认证

# 查看集群信息
cluster info
cluster nodes 
flushdb # 清空当前数据
flushall # 清空当前节点所有数据
```

当redis连接池数量不够时，会抛出异常。如果连接池数目足够支撑项目，那么不会因连接池数目少而异常。

idea断点调试，多线程，使用

`redis.clients.jedis.Client`

`org.springframework.data.redis.connection.DefaultStringRedisConnection`  去查看memory的连接数数据。



### redis操作命令

[官方命令操作集合](https://redis.io/commands)

#### 对value操作的命令

- exists(key)：确认一个key是否存在
- del(key)：删除一个key
- type(key)：返回值的类型
- keys(pattern)：返回满足给定pattern的所有key
- randomkey：随机返回key空间的一个key
- rename(oldname, newname)：将key由oldname重命名为newname，若newname存在则删除newname表示的key
- dbsize：返回当前数据库中key的数目
- expire：设定一个key的活动时间（s）
- ttl：获得一个key的活动时间
- select(index)：按索引查询
- move(key, dbindex)：将当前数据库中的key转移到有dbindex索引的数据库
- flushdb：删除当前选择数据库中的所有key
- flushall：删除所有数据库中的所有key

#### 对String操作的命令

对应opsForValue()

- set(key, value)：给数据库中名称为key的string赋予值value
- get(key)：返回数据库中名称为key的string的value
- getset(key, value)：给名称为key的string赋予上一次的value
- mget(key1, key2,…, key N)：返回库中多个string（它们的名称为key1，key2…）的value
- setnx(key, value)：如果不存在名称为key的string，则向库中添加string，名称为key，值为value
- setex(key, time, value)：向库中添加string（名称为key，值为value）同时，设定过期时间time
- mset(key1, value1, key2, value2,…key N, value N)：同时给多个string赋值，名称为key i的string赋值value i
- msetnx(key1, value1, key2, value2,…key N, value N)：如果所有名称为key i的string都不存在，则向库中添加string，名称key i赋值为value i
- incr(key)：名称为key的string增1操作
- incrby(key, integer)：名称为key的string增加integer
- decr(key)：名称为key的string减1操作
- decrby(key, integer)：名称为key的string减少integer
- append(key, value)：名称为key的string的值附加value
- substr(key, start, end)：返回名称为key的string的value的子串

#### 对List操作的命令

- rpush(key, value)：在名称为key的list尾添加一个值为value的元素
- lpush(key, value)：在名称为key的list头添加一个值为value的 元素
- llen(key)：返回名称为key的list的长度
- lrange(key, start, end)：返回名称为key的list中start至end之间的元素（下标从0开始，下同）
- ltrim(key, start, end)：截取名称为key的list，保留start至end之间的元素
- lindex(key, index)：返回名称为key的list中index位置的元素
- lset(key, index, value)：给名称为key的list中index位置的元素赋值为value
- lrem(key, count, value)：删除count个名称为key的list中值为value的元素。count为0，删除所有值为value的元素，count>0从头至尾删除count个值为value的元素，count<0从尾到头删除|count|个值为value的元素。 lpop(key)：返回并删除名称为key的list中的首元素 rpop(key)：返回并删除名称为key的list中的尾元素 blpop(key1, key2,… key N, timeout)：lpop命令的block版本。即当timeout为0时，若遇到名称为key i的list不存在或该list为空，则命令结束。如果timeout>0，则遇到上述情况时，等待timeout秒，如果问题没有解决，则对keyi+1开始的list执行pop操作。
- brpop(key1, key2,… key N, timeout)：rpop的block版本。参考上一命令。
- rpoplpush(srckey, dstkey)：返回并删除名称为srckey的list的尾元素，并将该元素添加到名称为dstkey的list的头部



#### 对Set操作的命令

- sadd(key, member)：向名称为key的set中添加元素member
- srem(key, member) ：删除名称为key的set中的元素member
- spop(key) ：随机返回并删除名称为key的set中一个元素
- smove(srckey, dstkey, member) ：将member元素从名称为srckey的集合移到名称为dstkey的集合
- scard(key) ：返回名称为key的set的基数
- sismember(key, member) ：测试member是否是名称为key的set的元素
- sinter(key1, key2,…key N) ：求交集
- sinterstore(dstkey, key1, key2,…key N) ：求交集并将交集保存到dstkey的集合
- sunion(key1, key2,…key N) ：求并集
- sunionstore(dstkey, key1, key2,…key N) ：求并集并将并集保存到dstkey的集合
- sdiff(key1, key2,…key N) ：求差集
- sdiffstore(dstkey, key1, key2,…key N) ：求差集并将差集保存到dstkey的集合
- smembers(key) ：返回名称为key的set的所有元素
- srandmember(key) ：随机返回名称为key的set的一个元素

#### 对zset（sorted set）操作的命令

- zadd(key, score, member)：向名称为key的zset中添加元素member，score用于排序。如果该元素已经存在，则根据score更新该元素的顺序。
- zrem(key, member) ：删除名称为key的zset中的元素member
- zincrby(key, increment, member) ：如果在名称为key的zset中已经存在元素member，则该元素的score增加increment；否则向集合中添加该元素，其score的值为increment
- zrank(key, member) ：返回名称为key的zset（元素已按score从小到大排序）中member元素的rank（即index，从0开始），若没有member元素，返回“nil”
- zrevrank(key, member) ：返回名称为key的zset（元素已按score从大到小排序）中member元素的rank（即index，从0开始），若没有member元素，返回“nil”
- zrange(key, start, end)：返回名称为key的zset（元素已按score从小到大排序）中的index从start到end的所有元素
- zrevrange(key, start, end)：返回名称为key的zset（元素已按score从大到小排序）中的index从start到end的所有元素
- zrangebyscore(key, min, max)：返回名称为key的zset中score >= min且score <= max的所有元素 zcard(key)：返回名称为key的zset的基数 zscore(key, element)：返回名称为key的zset中元素element的score zremrangebyrank(key, min, max)：删除名称为key的zset中rank >= min且rank <= max的所有元素 zremrangebyscore(key, min, max) ：删除名称为key的zset中score >= min且score <= max的所有元素
- zunionstore / zinterstore(dstkeyN, key1,…,keyN, WEIGHTS w1,…wN, AGGREGATE SUM|MIN|MAX)：对N个zset求并集和交集，并将最后的集合保存在dstkeyN中。对于集合中每一个元素的score，在进行AGGREGATE运算前，都要乘以对于的WEIGHT参数。如果没有提供WEIGHT，默认为1。默认的AGGREGATE是SUM，即结果集合中元素的score是所有集合对应元素进行SUM运算的值，而MIN和MAX是指，结果集合中元素的score是所有集合对应元素中最小值和最大值。

#### 对Hash操作的命令

- hset(key, field, value)：向名称为key的hash中添加元素field<—>value
- hget(key, field)：返回名称为key的hash中field对应的value
- hmget(key, field1, …,field N)：返回名称为key的hash中field i对应的value
- hmset(key, field1, value1,…,field N, value N)：向名称为key的hash中添加元素field i<—>value i
- hincrby(key, field, integer)：将名称为key的hash中field的value增加integer
- hexists(key, field)：名称为key的hash中是否存在键为field的域
- hdel(key, field)：删除名称为key的hash中键为field的域
- hlen(key)：返回名称为key的hash中元素个数
- hkeys(key)：返回名称为key的hash中所有键
- hvals(key)：返回名称为key的hash中所有键对应的value
- hgetall(key)：返回名称为key的hash中所有的键（field）及其对应的value

#### 持久化

- save：将数据同步保存到磁盘
- bgsave：将数据异步保存到磁盘
- lastsave：返回上次成功将数据保存到磁盘的Unix时戳
- shundown：将数据同步保存到磁盘，然后关闭服务

#### 远程服务控制

- info：提供服务器的信息和统计
- monitor：实时转储收到的请求
- slaveof：改变复制策略设置
- config：在运行时配置Redis服务器



## SpringDataRedis

官方文档：[https://docs.spring.io/spring-data/data-redis/docs/current/reference/html/#cluster](https://docs.spring.io/spring-data/data-redis/docs/current/reference/html/#cluster)

Working with [Redis Cluster](https://redis.io/topics/cluster-spec) requires Redis Server version 3.0+. See the [Cluster Tutorial](https://redis.io/topics/cluster-tutorial) for more information.

Redis 单机配置：application.properties

```properties
# Redis 单机配置
# Redis数据库索引（默认为0）
spring.redis.database=0
# Redis服务器地址
spring.redis.host=192.168.10.128
# Redis服务器连接端口
spring.redis.port=6379
# Redis服务器连接密码（默认为空）
spring.redis.password=123qwe
# 连接池最大连接数（使用负值表示没有限制）
spring.redis.pool.max-active=8
# 连接池最大阻塞等待时间（使用负值表示没有限制）
spring.redis.pool.max-wait=-1
# 连接池中的最大空闲连接
spring.redis.pool.max-idle=8
# 连接池中的最小空闲连接
spring.redis.pool.min-idle=0
# 连接超时时间（毫秒）
spring.redis.timeout=0
```

Redis-Cluster 集群配置：

```yaml
# 集群模式：单机的配置会被覆盖，max-redirects 最大重定向数目, nodes:以逗号分隔的“主机：端口”
---
spring:
  profiles: cluster
  redis:
    cluster:
      nodes: master.docker:7001,master.docker:7002,master.docker:7003,master.docker:7004,master.docker:7005,master.docker:7006
      max-redirects: 3 # 最好大于等于所有节点数目，因为槽点获取会有多次
    pool:
      max-active: 100
```



### 调试Redis技巧

如果是集群方式：JedisClusterConnectionHandler 集群连接处理

```java
// redis.clients.jedis.JedisClusterConnectionHandler#initializeSlotsCache

private void initializeSlotsCache(Set<HostAndPort> startNodes, GenericObjectPoolConfig poolConfig,
                                    int connectionTimeout, int soTimeout, String password, String clientName) {
    // 循环集群模式每个节点配置
	for (HostAndPort hostAndPort : startNodes) {
      Jedis jedis = null;
      try {
        jedis = new Jedis(hostAndPort.getHost(), hostAndPort.getPort(), connectionTimeout, soTimeout);
        if (password != null) {
          jedis.auth(password);
        }
        if (clientName != null) {
          jedis.clientSetname(clientName);
        }
		// 发现每个节点和Slot分配信息：核心得到每个服务的内部ip
        cache.discoverClusterNodesAndSlots(jedis);
        break;
      } catch (JedisConnectionException e) {
        // try next nodes
      } finally {
        if (jedis != null) {
          jedis.close();
        }
      }
    }
}
```

#### JedisClusterInfoCache 获取集群缓存信息

```java
// JedisClusterInfoCache
public void discoverClusterNodesAndSlots(Jedis jedis) {
    w.lock();

    try {
      reset();
      List<Object> slots = jedis.clusterSlots();
	  // 循环槽点
      for (Object slotInfoObj : slots) {
        List<Object> slotInfo = (List<Object>) slotInfoObj;

        if (slotInfo.size() <= MASTER_NODE_INDEX) {
          continue;
        }

        List<Integer> slotNums = getAssignedSlotArray(slotInfo);

        // hostInfos
        int size = slotInfo.size();
        for (int i = MASTER_NODE_INDEX; i < size; i++) {
          List<Object> hostInfos = (List<Object>) slotInfo.get(i);
          if (hostInfos.size() <= 0) {
            continue;
          }
		  // 生成host和port
          HostAndPort targetNode = generateHostAndPort(hostInfos);
          setupNodeIfNotExist(targetNode);
          if (i == MASTER_NODE_INDEX) {
            assignSlotsToNode(slotNums, targetNode);
          }
        }
      }
    } finally {
      w.unlock();
    }
}
```

#### 执行类：BinaryJedisCluster

```java
// 调用stringRedisTemplate.opsForValue().set(data,data);实际操作如下
// 调用redis.clients.jedis.BinaryJedisCluster#set(byte[], byte[])
// JedisClusterConnectionHandler 是connectionHandler
@Override
public String set(final byte[] key, final byte[] value) {
return new JedisClusterCommand<String>(connectionHandler, maxAttempts) {
  @Override
  public String execute(Jedis connection) {
	return connection.set(key, value);
  }
}.runBinary(key);
}

// 调用redis.clients.jedis.JedisClusterCommand#runBinary(byte[])
public T runBinary(byte[] key) {
	if (key == null) {
	  throw new JedisClusterException("No way to dispatch this command to Redis Cluster.");
	}
	
	// 重试机制
	return runWithRetries(JedisClusterCRC16.getSlot(key), this.maxAttempts, false, false);
}

// attempts 默认值配置，会进行减一操作
private T runWithRetries(final int slot, int attempts, boolean tryRandomNode, boolean asking) {
    if (attempts <= 0) {
      throw new JedisClusterMaxRedirectionsException("Too many Cluster redirections?");
    }

    Jedis connection = null;
    try {

      if (asking) {
        // TODO: Pipeline asking with the original command to make it
        // faster....
        connection = askConnection.get();
        connection.asking();

        // if asking success, reset asking flag
        asking = false;
      } else {
		// 随机node
        if (tryRandomNode) {
          connection = connectionHandler.getConnection();
        } else {
		  // 默认从slot槽获取连接
          connection = connectionHandler.getConnectionFromSlot(slot);
        }
      }

      return execute(connection);

    } catch (JedisNoReachableClusterNodeException jnrcne) {
      throw jnrcne;
    } catch (JedisConnectionException jce) {
      // release current connection before recursion
      releaseConnection(connection);
      connection = null;

      if (attempts <= 1) {
        //We need this because if node is not reachable anymore - we need to finally initiate slots renewing,
        //or we can stuck with cluster state without one node in opposite case.
        //But now if maxAttempts = 1 or 2 we will do it too often. For each time-outed request.
        //TODO make tracking of successful/unsuccessful operations for node - do renewing only
        //if there were no successful responses from this node last few seconds
        this.connectionHandler.renewSlotCache();
      }

      return runWithRetries(slot, attempts - 1, tryRandomNode, asking);
    } catch (JedisRedirectionException jre) {
      // if MOVED redirection occurred,
      if (jre instanceof JedisMovedDataException) {
        // it rebuilds cluster's slot cache
        // recommended by Redis cluster specification
        this.connectionHandler.renewSlotCache(connection);
      }

      // release current connection before recursion or renewing
      releaseConnection(connection);
      connection = null;

      if (jre instanceof JedisAskDataException) {
        asking = true;
        askConnection.set(this.connectionHandler.getConnectionFromNode(jre.getTargetNode()));
      } else if (jre instanceof JedisMovedDataException) {
      } else {
        throw new JedisClusterException(jre);
      }

      return runWithRetries(slot, attempts - 1, false, asking);
    } finally {
      releaseConnection(connection);
    }
}

```

#### JedisSlotBasedConnectionHandler

```java
public Jedis getConnectionFromSlot(int slot) {
    // 缓存获取
	JedisPool connectionPool = cache.getSlotPool(slot);
	if (connectionPool != null) {
	  // It can't guaranteed to get valid connection because of node
	  // assignment
	  return connectionPool.getResource();
	} else {
	  renewSlotCache(); //It's abnormal situation for cluster mode, that we have just nothing for slot, try to rediscover state
	  connectionPool = cache.getSlotPool(slot);
	  if (connectionPool != null) {
		return connectionPool.getResource();
	  } else {
		//no choice, fallback to new connection to random node
		return getConnection();
	  }
	}
}
```

#### JedisClusterCRC16

```java
// 根据key获取slot值
public static int getSlot(String key) {
    key = JedisClusterHashTagUtil.getHashTag(key);
    // optimization with modulo operator with power of 2
    // equivalent to getCRC16(key) % 16384
    return getCRC16(key) & (16384 - 1);
}
```

### API使用说明

#### RedisTempalte类API

| 方　　法         | 子API接口                 | 描　　述                                               |
| ---------------- | ------------------------- | ------------------------------------------------------ |
| opsForValue()    | ValueOperations<K, V>     | 操作具有简单值的条目                                   |
| opsForList()     | ListOperations<K, V>      | 操作具有list值的条目                                   |
| opsForSet()      | SetOperations<K, V>       | 操作具有set值的条目                                    |
| opsForZSet()     | ZSetOperations<K, V>      | 操作具有ZSet值（排序的set）的条目                      |
| opsForHash()     | HashOperations<K, HK, HV> | 操作具有hash值的条目                                   |
| boundValueOps(K) | BoundValueOperations<K,V> | 以绑定指定key的方式，操作具有简单值的条目              |
| boundListOps(K)  | BoundListOperations<K,V>  | 以绑定指定key的方式，操作具有list值的条目              |
| boundSetOps(K)   | BoundSetOperations<K,V>   | 以绑定指定key的方式，操作具有set值的条目               |
| boundZSet(K)     | BoundZSetOperations<K,V>  | 以绑定指定key的方式，操作具有ZSet值（排序的set）的条目 |
| boundHashOps(K)  | BoundHashOperations<K,V>  | 以绑定指定key的方式，操作具有hash值的条目              |

#### BoundValueOperations 类API

```java
String key = "hexiaowu";
// 绑定key，获取操作
BoundValueOperations stringTemplate = redisTemplate.boundValueOps(key);
```

**API说明**

| 方法名                                         | 方法描述                                                     |
| ---------------------------------------------- | ------------------------------------------------------------ |
| void set(V value)                              | 设定key对应的vlaue值                                         |
| void set(V value,long offset)                  | 将value值从第offset位开始替换                                |
| void set(V value, long timeout, TimeUnit unit) | 设置value的超时时间,timeout为数字,unit为单位,例如天,小时等   |
| Boolean setIfAbsent(V value)                   | 判断key是否有对应的value,如果有,则返回false,如果没有,添加,返回true |
| V get()                                        | 返回key对应的value                                           |
| String get(long start, long end)               | 从start开始,到end结束,截取value的值                          |
| V getAndSet(V value)                           | 替换value的值,并且返回value的旧值                            |
| Long increment(long delta)                     | 如果value是数字类型的字符串,那么增加delta,并且返回新的value  |
| Double increment(double delta)                 | 如果value是数字类型的字符串,那么增加delta,并且返回新的value  |
| Integer append(String value)                   | 在value值后面进行添加,并且返回新value的长度                  |
| Long size()                                    | 返回value的长度                                              |
| Boolean expire(long var1, TimeUnit var3)       | 设置key的缓存时间,var1为数字,unit为单位,例如天,小时等,返回是否设置成功 |
| Boolean expireAt(Date var1)                    | 设置key的具体到期时间,并且返回是否设置成功                   |
| Long getExpire()                               | 返回key的剩余缓存时间,单位:秒                                |
| K getKey()                                     | 返回key的名称                                                |
| DataType getType()                             | 获取key的类型                                                |
| Boolean persist()                              | 删除key的缓存时间                                            |
| void rename(K var1)                            | 修改key的名称                                                |



### 源码分析

#### StringRedisTemplate 

主要继承`RedisTemplate`，序列化key和value采用`StringRedisSerializer`

```java
public class StringRedisTemplate extends RedisTemplate<String, String> {

	/**
	 * 构造方法：采用StringRedisSerializer序列化机制
	 */
	public StringRedisTemplate() {
		RedisSerializer<String> stringSerializer = new StringRedisSerializer();
		setKeySerializer(stringSerializer);
		setValueSerializer(stringSerializer);
		setHashKeySerializer(stringSerializer);
		setHashValueSerializer(stringSerializer);
	}

	/**
	 * 构造一个使用的StringRedisTemplate
	 */
	public StringRedisTemplate(RedisConnectionFactory connectionFactory) {
		this();
		setConnectionFactory(connectionFactory);
		afterPropertiesSet();
	}

	protected RedisConnection preProcessConnection(RedisConnection connection, boolean existingConnection) {
		return new DefaultStringRedisConnection(connection);
	}
}
```

String序列化类

```java
public class StringRedisSerializer implements RedisSerializer<String> {

	private final Charset charset;
	// 默认字符编码UTF8
	public StringRedisSerializer() {
		this(Charset.forName("UTF8"));
	}

	public StringRedisSerializer(Charset charset) {
		Assert.notNull(charset, "Charset must not be null!");
		this.charset = charset;
	}
	
	// 反序列化
	public String deserialize(byte[] bytes) {
		return (bytes == null ? null : new String(bytes, charset));
	}

	// 序列化
	public byte[] serialize(String string) {
		return (string == null ? null : string.getBytes(charset));
	}
}
```

#### RedisTemplate 

可以自定义的序列化方式：keySerializer、valueSerializer、hashKeySerializer、hashValueSerializer

操作单例对象如：ValueOperations、ListOperations、SetOperations、ZSetOperations、GeoOperations、HyperLogLogOperations 等。

afterPropertiesSet 默认配置：JdkSerializationRedisSerializer

```java
public class RedisTemplate<K, V> extends RedisAccessor implements RedisOperations<K, V>, BeanClassLoaderAware {

	private boolean enableTransactionSupport = false;
	private boolean exposeConnection = false;
	private boolean initialized = false;
	private boolean enableDefaultSerializer = true;
	private RedisSerializer<?> defaultSerializer;
	private ClassLoader classLoader;

	private RedisSerializer keySerializer = null;
	private RedisSerializer valueSerializer = null;
	private RedisSerializer hashKeySerializer = null;
	private RedisSerializer hashValueSerializer = null;
	private RedisSerializer<String> stringSerializer = new StringRedisSerializer();

	private ScriptExecutor<K> scriptExecutor;

	// cache singleton objects (where possible)，创建单例对象
	private ValueOperations<K, V> valueOps;
	private ListOperations<K, V> listOps;
	private SetOperations<K, V> setOps;
	private ZSetOperations<K, V> zSetOps;
	private GeoOperations<K, V> geoOps;
	private HyperLogLogOperations<K, V> hllOps;

	/**
	 * Constructs a new <code>RedisTemplate</code> instance.
	 */
	public RedisTemplate() {}

	public void afterPropertiesSet() {

		super.afterPropertiesSet();

		boolean defaultUsed = false;
	
		// 默认jdk序列化模式
		if (defaultSerializer == null) {

			defaultSerializer = new JdkSerializationRedisSerializer(
					classLoader != null ? classLoader : this.getClass().getClassLoader());
		}

		if (enableDefaultSerializer) {

			if (keySerializer == null) {
				keySerializer = defaultSerializer;
				defaultUsed = true;
			}
			if (valueSerializer == null) {
				valueSerializer = defaultSerializer;
				defaultUsed = true;
			}
			if (hashKeySerializer == null) {
				hashKeySerializer = defaultSerializer;
				defaultUsed = true;
			}
			if (hashValueSerializer == null) {
				hashValueSerializer = defaultSerializer;
				defaultUsed = true;
			}
		}

		if (enableDefaultSerializer && defaultUsed) {
			Assert.notNull(defaultSerializer, "default serializer null and not all serializers initialized");
		}

		if (scriptExecutor == null) {
			this.scriptExecutor = new DefaultScriptExecutor<K>(this);
		}

		initialized = true;
	}



	public <T> T execute(RedisCallback<T> action, boolean exposeConnection, boolean pipeline) {
		Assert.isTrue(initialized, "template not initialized; call afterPropertiesSet() before using it");
		Assert.notNull(action, "Callback object must not be null");

		RedisConnectionFactory factory = getConnectionFactory();
		RedisConnection conn = null;
		try {

			if (enableTransactionSupport) {
				// only bind resources in case of potential transaction synchronization
				conn = RedisConnectionUtils.bindConnection(factory, enableTransactionSupport);
			} else {
				conn = RedisConnectionUtils.getConnection(factory);
			}

			boolean existingConnection = TransactionSynchronizationManager.hasResource(factory);

			RedisConnection connToUse = preProcessConnection(conn, existingConnection);

			boolean pipelineStatus = connToUse.isPipelined();
			if (pipeline && !pipelineStatus) {
				connToUse.openPipeline();
			}

			RedisConnection connToExpose = (exposeConnection ? connToUse : createRedisConnectionProxy(connToUse));
			T result = action.doInRedis(connToExpose);

			// close pipeline
			if (pipeline && !pipelineStatus) {
				connToUse.closePipeline();
			}

			// TODO: any other connection processing?
			return postProcessResult(result, connToUse, existingConnection);
		} finally {
			RedisConnectionUtils.releaseConnection(conn, factory);
		}
	}


	public List<Object> executePipelined(final SessionCallback<?> session, final RedisSerializer<?> resultSerializer) {
		Assert.isTrue(initialized, "template not initialized; call afterPropertiesSet() before using it");
		Assert.notNull(session, "Callback object must not be null");

		RedisConnectionFactory factory = getConnectionFactory();
		// bind connection
		RedisConnectionUtils.bindConnection(factory, enableTransactionSupport);
		try {
			return execute(new RedisCallback<List<Object>>() {
				public List<Object> doInRedis(RedisConnection connection) throws DataAccessException {
					connection.openPipeline();
					boolean pipelinedClosed = false;
					try {
						Object result = executeSession(session);
						if (result != null) {
							throw new InvalidDataAccessApiUsageException(
									"Callback cannot return a non-null value as it gets overwritten by the pipeline");
						}
						List<Object> closePipeline = connection.closePipeline();
						pipelinedClosed = true;
						return deserializeMixedResults(closePipeline, resultSerializer, hashKeySerializer, hashValueSerializer);
					} finally {
						if (!pipelinedClosed) {
							connection.closePipeline();
						}
					}
				}
			});
		} finally {
			RedisConnectionUtils.unbindConnection(factory);
		}
	}

	protected RedisConnection createRedisConnectionProxy(RedisConnection pm) {
		Class<?>[] ifcs = ClassUtils.getAllInterfacesForClass(pm.getClass(), getClass().getClassLoader());
		return (RedisConnection) Proxy.newProxyInstance(pm.getClass().getClassLoader(), ifcs,
				new CloseSuppressingInvocationHandler(pm));
	}

	protected RedisConnection preProcessConnection(RedisConnection connection, boolean existingConnection) {
		return connection;
	}

	protected <T> T postProcessResult(T result, RedisConnection conn, boolean existingConnection) {
		return result;
	}


	@SuppressWarnings("unchecked")
	private byte[] rawKey(Object key) {
		Assert.notNull(key, "non null key required");
		if (keySerializer == null && key instanceof byte[]) {
			return (byte[]) key;
		}
		return keySerializer.serialize(key);
	}

	private byte[] rawString(String key) {
		return stringSerializer.serialize(key);
	}

	@SuppressWarnings("unchecked")
	private byte[] rawValue(Object value) {
		if (valueSerializer == null && value instanceof byte[]) {
			return (byte[]) value;
		}
		return valueSerializer.serialize(value);
	}

	private byte[][] rawKeys(Collection<K> keys) {
		final byte[][] rawKeys = new byte[keys.size()][];

		int i = 0;
		for (K key : keys) {
			rawKeys[i++] = rawKey(key);
		}

		return rawKeys;
	}

	@SuppressWarnings("unchecked")
	private K deserializeKey(byte[] value) {
		return keySerializer != null ? (K) keySerializer.deserialize(value) : (K) value;
	}

	@SuppressWarnings({ "unchecked", "rawtypes" })
	private List<Object> deserializeMixedResults(List<Object> rawValues, RedisSerializer valueSerializer,
			RedisSerializer hashKeySerializer, RedisSerializer hashValueSerializer) {
		if (rawValues == null) {
			return null;
		}
		List<Object> values = new ArrayList<Object>();
		for (Object rawValue : rawValues) {
			if (rawValue instanceof byte[] && valueSerializer != null) {
				values.add(valueSerializer.deserialize((byte[]) rawValue));
			} else if (rawValue instanceof List) {
				// Lists are the only potential Collections of mixed values....
				values.add(deserializeMixedResults((List) rawValue, valueSerializer, hashKeySerializer, hashValueSerializer));
			} else if (rawValue instanceof Set && !(((Set) rawValue).isEmpty())) {
				values.add(deserializeSet((Set) rawValue, valueSerializer));
			} else if (rawValue instanceof Map && !(((Map) rawValue).isEmpty())
					&& ((Map) rawValue).values().iterator().next() instanceof byte[]) {
				values.add(SerializationUtils.deserialize((Map) rawValue, hashKeySerializer, hashValueSerializer));
			} else {
				values.add(rawValue);
			}
		}
		return values;
	}

	@SuppressWarnings({ "rawtypes", "unchecked" })
	private Set<?> deserializeSet(Set rawSet, RedisSerializer valueSerializer) {
		if (rawSet.isEmpty()) {
			return rawSet;
		}
		Object setValue = rawSet.iterator().next();
		if (setValue instanceof byte[] && valueSerializer != null) {
			return (SerializationUtils.deserialize((Set) rawSet, valueSerializer));
		} else if (setValue instanceof Tuple) {
			return convertTupleValues(rawSet, valueSerializer);
		} else {
			return rawSet;
		}
	}

	@SuppressWarnings({ "unchecked", "rawtypes" })
	private Set<TypedTuple<V>> convertTupleValues(Set<Tuple> rawValues, RedisSerializer valueSerializer) {
		Set<TypedTuple<V>> set = new LinkedHashSet<TypedTuple<V>>(rawValues.size());
		for (Tuple rawValue : rawValues) {
			Object value = rawValue.getValue();
			if (valueSerializer != null) {
				value = valueSerializer.deserialize(rawValue.getValue());
			}
			set.add(new DefaultTypedTuple(value, rawValue.getScore()));
		}
		return set;
	}

	//
	// RedisOperations-- 操作
	//

	public List<Object> exec() {
		List<Object> results = execRaw();
		if (getConnectionFactory().getConvertPipelineAndTxResults()) {
			return deserializeMixedResults(results, valueSerializer, hashKeySerializer, hashValueSerializer);
		} else {
			return results;
		}
	}

	public List<Object> exec(RedisSerializer<?> valueSerializer) {
		return deserializeMixedResults(execRaw(), valueSerializer, valueSerializer, valueSerializer);
	}

	protected List<Object> execRaw() {
		return execute(new RedisCallback<List<Object>>() {
			public List<Object> doInRedis(RedisConnection connection) throws DataAccessException {
				return connection.exec();
			}
		});
	}

	public void delete(K key) {
		final byte[] rawKey = rawKey(key);

		execute(new RedisCallback<Object>() {

			public Object doInRedis(RedisConnection connection) {
				connection.del(rawKey);
				return null;
			}
		}, true);
	}

	public void delete(Collection<K> keys) {
		if (CollectionUtils.isEmpty(keys)) {
			return;
		}

		final byte[][] rawKeys = rawKeys(keys);

		execute(new RedisCallback<Object>() {

			public Object doInRedis(RedisConnection connection) {
				connection.del(rawKeys);
				return null;
			}
		}, true);
	}

	public Boolean hasKey(K key) {
		final byte[] rawKey = rawKey(key);

		return execute(new RedisCallback<Boolean>() {

			public Boolean doInRedis(RedisConnection connection) {
				return connection.exists(rawKey);
			}
		}, true);
	}

	public Boolean expire(K key, final long timeout, final TimeUnit unit) {
		final byte[] rawKey = rawKey(key);
		final long rawTimeout = TimeoutUtils.toMillis(timeout, unit);

		return execute(new RedisCallback<Boolean>() {

			public Boolean doInRedis(RedisConnection connection) {
				try {
					return connection.pExpire(rawKey, rawTimeout);
				} catch (Exception e) {
					// Driver may not support pExpire or we may be running on Redis 2.4
					return connection.expire(rawKey, TimeoutUtils.toSeconds(timeout, unit));
				}
			}
		}, true);
	}

	public Boolean expireAt(K key, final Date date) {
		final byte[] rawKey = rawKey(key);

		return execute(new RedisCallback<Boolean>() {

			public Boolean doInRedis(RedisConnection connection) {
				try {
					return connection.pExpireAt(rawKey, date.getTime());
				} catch (Exception e) {
					return connection.expireAt(rawKey, date.getTime() / 1000);
				}
			}
		}, true);
	}

	public void convertAndSend(String channel, Object message) {
		Assert.hasText(channel, "a non-empty channel is required");

		final byte[] rawChannel = rawString(channel);
		final byte[] rawMessage = rawValue(message);

		execute(new RedisCallback<Object>() {

			public Object doInRedis(RedisConnection connection) {
				connection.publish(rawChannel, rawMessage);
				return null;
			}
		}, true);
	}

	//
	// Value operations
	//

	public Long getExpire(K key) {
		final byte[] rawKey = rawKey(key);

		return execute(new RedisCallback<Long>() {

			public Long doInRedis(RedisConnection connection) {
				return connection.ttl(rawKey);
			}
		}, true);
	}

	public Long getExpire(K key, final TimeUnit timeUnit) {
		final byte[] rawKey = rawKey(key);

		return execute(new RedisCallback<Long>() {

			public Long doInRedis(RedisConnection connection) {
				try {
					return connection.pTtl(rawKey, timeUnit);
				} catch (Exception e) {
					// Driver may not support pTtl or we may be running on Redis 2.4
					return connection.ttl(rawKey, timeUnit);
				}
			}
		}, true);
	}

	@SuppressWarnings("unchecked")
	public Set<K> keys(K pattern) {
		final byte[] rawKey = rawKey(pattern);

		Set<byte[]> rawKeys = execute(new RedisCallback<Set<byte[]>>() {

			public Set<byte[]> doInRedis(RedisConnection connection) {
				return connection.keys(rawKey);
			}
		}, true);

		return keySerializer != null ? SerializationUtils.deserialize(rawKeys, keySerializer) : (Set<K>) rawKeys;
	}

	public Boolean persist(K key) {
		final byte[] rawKey = rawKey(key);

		return execute(new RedisCallback<Boolean>() {

			public Boolean doInRedis(RedisConnection connection) {
				return connection.persist(rawKey);
			}
		}, true);
	}

	public Boolean move(K key, final int dbIndex) {
		final byte[] rawKey = rawKey(key);

		return execute(new RedisCallback<Boolean>() {

			public Boolean doInRedis(RedisConnection connection) {
				return connection.move(rawKey, dbIndex);
			}
		}, true);
	}

	public K randomKey() {
		byte[] rawKey = execute(new RedisCallback<byte[]>() {

			public byte[] doInRedis(RedisConnection connection) {
				return connection.randomKey();
			}
		}, true);

		return deserializeKey(rawKey);
	}

	public void rename(K oldKey, K newKey) {
		final byte[] rawOldKey = rawKey(oldKey);
		final byte[] rawNewKey = rawKey(newKey);

		execute(new RedisCallback<Object>() {

			public Object doInRedis(RedisConnection connection) {
				connection.rename(rawOldKey, rawNewKey);
				return null;
			}
		}, true);
	}

	public Boolean renameIfAbsent(K oldKey, K newKey) {
		final byte[] rawOldKey = rawKey(oldKey);
		final byte[] rawNewKey = rawKey(newKey);

		return execute(new RedisCallback<Boolean>() {

			public Boolean doInRedis(RedisConnection connection) {
				return connection.renameNX(rawOldKey, rawNewKey);
			}
		}, true);
	}

	public DataType type(K key) {
		final byte[] rawKey = rawKey(key);

		return execute(new RedisCallback<DataType>() {

			public DataType doInRedis(RedisConnection connection) {
				return connection.type(rawKey);
			}
		}, true);
	}

	public byte[] dump(K key) {
		final byte[] rawKey = rawKey(key);

		return execute(new RedisCallback<byte[]>() {
			public byte[] doInRedis(RedisConnection connection) {
				return connection.dump(rawKey);
			}
		}, true);
	}

	public void restore(K key, final byte[] value, long timeToLive, TimeUnit unit) {
		final byte[] rawKey = rawKey(key);
		final long rawTimeout = TimeoutUtils.toMillis(timeToLive, unit);

		execute(new RedisCallback<Object>() {
			public Boolean doInRedis(RedisConnection connection) {
				connection.restore(rawKey, rawTimeout, value);
				return null;
			}
		}, true);
	}

	public void multi() {
		execute(new RedisCallback<Object>() {

			public Object doInRedis(RedisConnection connection) throws DataAccessException {
				connection.multi();
				return null;
			}
		}, true);
	}

	public void discard() {
		execute(new RedisCallback<Object>() {

			public Object doInRedis(RedisConnection connection) throws DataAccessException {
				connection.discard();
				return null;
			}
		}, true);
	}

	public void watch(K key) {
		final byte[] rawKey = rawKey(key);

		execute(new RedisCallback<Object>() {

			public Object doInRedis(RedisConnection connection) {
				connection.watch(rawKey);
				return null;
			}
		}, true);
	}




	// Sort operations

	@SuppressWarnings("unchecked")
	public List<V> sort(SortQuery<K> query) {
		return sort(query, valueSerializer);
	}

	public <T> List<T> sort(SortQuery<K> query, RedisSerializer<T> resultSerializer) {
		final byte[] rawKey = rawKey(query.getKey());
		final SortParameters params = QueryUtils.convertQuery(query, stringSerializer);

		List<byte[]> vals = execute(new RedisCallback<List<byte[]>>() {

			public List<byte[]> doInRedis(RedisConnection connection) throws DataAccessException {
				return connection.sort(rawKey, params);
			}
		}, true);

		return SerializationUtils.deserialize(vals, resultSerializer);
	}


	public Long sort(SortQuery<K> query, K storeKey) {
		final byte[] rawStoreKey = rawKey(storeKey);
		final byte[] rawKey = rawKey(query.getKey());
		final SortParameters params = QueryUtils.convertQuery(query, stringSerializer);

		return execute(new RedisCallback<Long>() {

			public Long doInRedis(RedisConnection connection) throws DataAccessException {
				return connection.sort(rawKey, params, rawStoreKey);
			}
		}, true);
	}

	public BoundValueOperations<K, V> boundValueOps(K key) {
		return new DefaultBoundValueOperations<K, V>(key, this);
	}

	public ValueOperations<K, V> opsForValue() {
		if (valueOps == null) {
			valueOps = new DefaultValueOperations<K, V>(this);
		}
		return valueOps;
	}

	public ListOperations<K, V> opsForList() {
		if (listOps == null) {
			listOps = new DefaultListOperations<K, V>(this);
		}
		return listOps;
	}

	public BoundListOperations<K, V> boundListOps(K key) {
		return new DefaultBoundListOperations<K, V>(key, this);
	}

	public BoundSetOperations<K, V> boundSetOps(K key) {
		return new DefaultBoundSetOperations<K, V>(key, this);
	}

	public SetOperations<K, V> opsForSet() {
		if (setOps == null) {
			setOps = new DefaultSetOperations<K, V>(this);
		}
		return setOps;
	}

	public BoundZSetOperations<K, V> boundZSetOps(K key) {
		return new DefaultBoundZSetOperations<K, V>(key, this);
	}

	public ZSetOperations<K, V> opsForZSet() {
		if (zSetOps == null) {
			zSetOps = new DefaultZSetOperations<K, V>(this);
		}
		return zSetOps;
	}

	@Override
	public GeoOperations<K, V> opsForGeo() {

		if (geoOps == null) {
			geoOps = new DefaultGeoOperations<K, V>(this);
		}
		return geoOps;
	}


	@Override
	public BoundGeoOperations<K, V> boundGeoOps(K key) {
		return new DefaultBoundGeoOperations<K, V>(key, this);
	}

	@Override
	public HyperLogLogOperations<K, V> opsForHyperLogLog() {

		if (hllOps == null) {
			hllOps = new DefaultHyperLogLogOperations<K, V>(this);
		}
		return hllOps;
	}

	public <HK, HV> BoundHashOperations<K, HK, HV> boundHashOps(K key) {
		return new DefaultBoundHashOperations<K, HK, HV>(key, this);
	}

	public <HK, HV> HashOperations<K, HK, HV> opsForHash() {
		return new DefaultHashOperations<K, HK, HV>(this);
	}

	public ClusterOperations<K, V> opsForCluster() {
		return new DefaultClusterOperations<K, V>(this);
	}

	@Override
	public void killClient(final String host, final int port) {

		execute(new RedisCallback<Void>() {

			@Override
			public Void doInRedis(RedisConnection connection) throws DataAccessException {
				connection.killClient(host, port);
				return null;
			}
		});
	}


}
```



### 自定义配置

针对数据的“序列化/反序列化”，提供了多种可选择策略(RedisSerializer)

- JdkSerializationRedisSerializer：POJO对象的存取场景，使用JDK本身序列化机制，将pojo类通过ObjectInputStream/ObjectOutputStream进行序列化操作，最终redis-server中将存储字节序列。是目前最常用的序列化策略。

- StringRedisSerializer：Key或者value为字符串的场景，根据指定的charset对数据的字节序列编码成string，是“new String(bytes, charset)”和“string.getBytes(charset)”的直接封装。是最轻量级和高效的策略。

- Jackson2JsonRedisSerializer：jackson-json工具提供了javabean与json之间的转换能力，可以将pojo实例序列化成json格式存储在redis中，也可以将json格式的数据转换成pojo实例。Jackson2JsonRedisSerializer反序列化list时，**强制类型转换出错**，可以采用String方式，然后再用ObjectMapper工具反序列化。**序列化对象存在默认无参构造函数**。

- OxmSerializer：提供了将javabean与xml之间的转换能力，目前可用的三方支持包括jaxb，apache-xmlbeans；redis存储的数据将是xml工具。不过使用此策略，编程将会有些难度，而且效率最低；不建议使用。【需要spring-oxm模块的支持】

- GenericJackson2JsonRedisSerializer:使用GenericJackson2JsonRedisSerializer序列化时，会保存序列化的对象的包名和类名，反序列化时以这个作为标示就可以反序列化成指定的对象。比Jackson2JsonRedisSerializer效率低，占用内存高。如果反序列化时，类名不一致就会失败。所以反序列化时包路径不一致，自然也就无法正确反序列化了。

  

#### RedisConfig配置说明

```java
@Configuration
public class RedisConfig {

    @Bean
    public RedisTemplate<String, Object> redisTemplate(RedisConnectionFactory redisConnectionFactory) {
        RedisTemplate<String, Object> template = new RedisTemplate<>();
        template.setConnectionFactory(redisConnectionFactory);
        // key序列化方式 String
        RedisSerializer<String> stringSerializer = new StringRedisSerializer();
        template.setKeySerializer(stringSerializer);
        template.setHashKeySerializer(stringSerializer);
        // value序列化方式 Json
        Jackson2JsonRedisSerializer jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer(Object.class);
        ObjectMapper objectMapper = new ObjectMapper();
        jackson2JsonRedisSerializer.setObjectMapper(objectMapper);
        template.setValueSerializer(jackson2JsonRedisSerializer);
        template.setHashValueSerializer(jackson2JsonRedisSerializer);
        return template;
    }

    @Bean
    public HashOperations<String, String, Object> hashOperations(RedisTemplate<String, Object> redisTemplate) {
        return redisTemplate.opsForHash();
    }

    @Bean
    public ValueOperations<String, String> valueOperations(RedisTemplate<String, String> redisTemplate) {
        return redisTemplate.opsForValue();
    }

    @Bean
    public ListOperations<String, Object> listOperations(RedisTemplate<String, Object> redisTemplate) {
        return redisTemplate.opsForList();
    }

    @Bean
    public SetOperations<String, Object> setOperations(RedisTemplate<String, Object> redisTemplate) {
        return redisTemplate.opsForSet();
    }

    @Bean
    public ZSetOperations<String, Object> zSetOperations(RedisTemplate<String, Object> redisTemplate) {
        return redisTemplate.opsForZSet();
    }
}
```

Redis获取缓存异常：java.lang.ClassCastException: java.util.LinkedHashMap cannot be cast to XXX。

出现这种异常，我需要自定义ObjectMapper，设置一些参数，而不是直接使用Jackson2JsonRedisSerializer类中黙认的ObjectMapper，看源代码可以知道，Jackson2JsonRedisSerializer中的ObjectMapper是直接使用new ObjectMapper()创建的，这样ObjectMapper会将Redis中的字符串反序列化为`java.util.LinkedHashMap`类型，导致后续Spring对其进行转换成报错。其实我们只要它返回Object类型就可以了。

```java
// 创建ObjectMapper
private ObjectMapper createObjectMapper(){
	ObjectMapper objectMapper = new ObjectMapper();
	objectMapper.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY);
	objectMapper.configure(MapperFeature.USE_ANNOTATIONS, false);
	objectMapper.configure(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES, false);
	objectMapper.configure(SerializationFeature.FAIL_ON_EMPTY_BEANS, false);
	// 此项必须配置，否则会报java.lang.ClassCastException: java.util.LinkedHashMap cannot be cast to XXX
	objectMapper.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL, JsonTypeInfo.As.PROPERTY);
	objectMapper.setSerializationInclusion(JsonInclude.Include.NON_NULL);
	return objectMapper;
}
```

##### GenericJackson2JsonRedisSerializer和Jackson2JsonRedisSerializer

注意此时的待序列化对象，必须有默认构造方法。否则反序列化失败。

注意`GenericJackson2JsonRedisSerializer`实际就是ObjectMapper 的配置修改了。而Jackson2JsonRedisSerializer则是原生

```java
public class Jackson2JsonRedisSerializer<T> implements RedisSerializer<T> {

	public static final Charset DEFAULT_CHARSET = Charset.forName("UTF-8");

	private final JavaType javaType;
	
	// java.util.LinkedHashMap cannot be cast to XXX。
	private ObjectMapper objectMapper = new ObjectMapper();

	/**
	 * Creates a new {@link Jackson2JsonRedisSerializer} for the given target {@link Class}.
	 * 
	 * @param type
	 */
	public Jackson2JsonRedisSerializer(Class<T> type) {
		this.javaType = getJavaType(type);
	}
}
```

GenericJackson2JsonRedisSerializer

```java
public class GenericJackson2JsonRedisSerializer implements RedisSerializer<Object> {

	private final ObjectMapper mapper;


	public GenericJackson2JsonRedisSerializer() {
		this((String) null);
	}


	public GenericJackson2JsonRedisSerializer(String classPropertyTypeName) {

		this(new ObjectMapper());

		mapper.registerModule(new SimpleModule().addSerializer(new NullValueSerializer(classPropertyTypeName)));
		// 序列化方式
		if (StringUtils.hasText(classPropertyTypeName)) {
			mapper.enableDefaultTypingAsProperty(DefaultTyping.NON_FINAL, classPropertyTypeName);
		} else {
			mapper.enableDefaultTyping(DefaultTyping.NON_FINAL, As.PROPERTY);
		}
	}

	public GenericJackson2JsonRedisSerializer(ObjectMapper mapper) {

		Assert.notNull(mapper, "ObjectMapper must not be null!");
		this.mapper = mapper;
	}
```

#### FastJson

```xml
<dependency>
    <groupId>com.alibaba</groupId>
    <artifactId>fastjson</artifactId>
    <version>${fastjson.version}</version>
</dependency>
```

Redis-配置

```java
// 一般的配置
private RedisSerializer<Object> genericFastJsonRedisSerializer() {    
	return  new GenericFastJsonRedisSerializer();
}
```

序列化结果：

```json
{
  "@type": "cn.selinx.boot.example.redis.action.vo.SysUser",
  "birthday": 1567414376952,
  "name": "cjp"
}

[
  {
    "@type": "cn.selinx.boot.example.redis.action.vo.SysUser",
    "birthday": 1567414397549,
    "name": "cjp0"
  },
  {
    "@type": "cn.selinx.boot.example.redis.action.vo.SysUser",
    "birthday": 1567414397549,
    "name": "cjp1"
  }
  ...
]
```

#### Jackson

Redis-配置

```java
// 一般的配置
private RedisSerializer<Object> genericJackson2JsonRedisSerializer() {    
	return  new GenericJackson2JsonRedisSerializer();
}
```

序列化结果：

```json
{
  "@class": "cn.selinx.boot.example.redis.action.vo.SysUser",
  "name": "cjp",
  "birthday": [
    "java.util.Date",
    1567415033884
  ]
}

[
  "java.util.ArrayList",
  [
    {
      "@class": "cn.selinx.boot.example.redis.action.vo.SysUser",
      "name": "cjp0",
      "birthday": [
        "java.util.Date",
        1567415036262
      ]
    },
    {
      "@class": "cn.selinx.boot.example.redis.action.vo.SysUser",
      "name": "cjp1",
      "birthday": [
        "java.util.Date",
        1567415036262
      ]
    },
    ...
  ]
]
```



